# ğŸ“š Taller de Procesamiento de Lenguaje Natural (RAG + GitHub Models)

Este proyecto es un **chatbot educativo** que responde preguntas **Ãºnicamente a partir de documentos proporcionados**.

EstÃ¡ diseÃ±ado para:
- Profesores e instructores
- Talleres de Procesamiento de Lenguaje Natural (NLP)
- Cursos universitarios
- Demostraciones prÃ¡cticas de IA generativa

El chatbot utiliza:
- **Retrieval-Augmented Generation (RAG)**
- **GitHub Models** (uso gratuito para fines educativos)
- Una interfaz sencilla con **Streamlit**

---

## âœ¨ Â¿QuÃ© hace este chatbot?

âœ… Responde preguntas solo usando los documentos cargados  
âœ… Rechaza preguntas fuera del contenido del curso  
âœ… Cita la fuente del documento utilizado en cada respuesta  
âœ… FÃ¡cil de personalizar (solo cambiar documentos)  
âœ… Se ejecuta localmente en el computador  

---

## ğŸ§  Â¿CÃ³mo funciona? (Nivel conceptual)

1. El profesor coloca los documentos del curso en la carpeta `docs/`
2. La aplicaciÃ³n genera representaciones vectoriales (embeddings)
3. Cuando un estudiante hace una pregunta:
   - Se buscan los fragmentos mÃ¡s relevantes
   - El modelo genera la respuesta usando **solo esos fragmentos**

Esto evita respuestas inventadas (alucinaciones) y mantiene el contenido controlado.

---

## ğŸ›  Requisitos

- Python **3.9 â€“ 3.14**
- Cuenta de GitHub
- ConexiÃ³n a Internet (para el modelo)

---

## ğŸš€ InstalaciÃ³n (Windows / macOS / Linux)

### 1ï¸âƒ£ Descargar o clonar el repositorio

```bash
git clone https://github.com/rczalez/Taller-NLP
```
### 2ï¸âƒ£ Crear y activar un entorno virtual
**Windows (PowerShell o CMD)**

```bash
python -m venv .venv
.venv\Scripts\activate
```
**macOS / Linux / Git Bash**

```bash
python -m venv .venv
source .venv/bin/activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

## ğŸ” ConfiguraciÃ³n de GitHub Models

### 1ï¸âƒ£ Crear un token de GitHub

- GitHub â†’ **Settings**
-  **Developer settings**
- **Personal access tokens** â†’ *Fine-grained token*

- Activar permiso: **Models (Read)**

### 2ï¸âƒ£ Crear archivo .env

Copia el archivo `env.example` y renÃ³mbralo como `.env`:

```bash
GITHUB_TOKEN=tu_token_de_github
GITHUB_MODELS_ENDPOINT=https://models.inference.ai.azure.com/chat/completions
MODEL_NAME=Meta-Llama-3.1-8B-Instruct
```

### â–¶ï¸ Ejecutar la aplicaciÃ³n

```bash
python -m streamlit run app.py
```
La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en:

http://localhost:8501


## ğŸ“‚ Agregar documentos del curso

1. Coloca los archivos en la carpeta docs/:
- PDF (`.pdf`)
- Word (`.docx`)
- Texto (`.txt`)

2. En la barra lateral de la aplicaciÃ³n:

- Haz clic en **Build / Rebuild Index**

3. Realiza preguntas relacionadas con el contenido

âš ï¸ Si cambias los documentos, debes reconstruir el Ã­ndice nuevamente.

## ğŸ§ª Ejemplos de preguntas

âœ”ï¸ *Â¿De que trata el libro?*

âœ”ï¸ *Â¿Cuales son los requerimientos tecnicos para el lector?*

âŒ *Â¿QuiÃ©n ganÃ³ el Ãºltimo mundial?* â†’ El chatbot rechazarÃ¡ la pregunta.

## ğŸ¤– Modelos compatibles (GitHub Models)

Los siguientes modelos han sido probados y funcionan correctamente con esta plantilla:

| Modelo | Uso recomendado |
|------|----------------|
| **Meta-Llama-3.1-8B-Instruct** | Mejor calidad general |
| **Phi-3-small-8k-instruct** | Respuestas mÃ¡s rÃ¡pidas |
| **Phi-3-medium-128k-instruct** | Documentos largos |
| **Mistral-7B-Instruct** | Alternativa equilibrada |

### Cambiar el modelo

Para utilizar un modelo diferente, edita el archivo `.env` y modifica la variable `MODEL_NAME`:

```env
MODEL_NAME=Meta-Llama-3.1-8B-Instruct
```
## ğŸ“ Estructura del Proyecto

La organizaciÃ³n del proyecto es la siguiente:

```text
.
â”œâ”€â”€ app.py               # Interfaz principal con Streamlit
â”œâ”€â”€ rag.py               # LÃ³gica de indexaciÃ³n y recuperaciÃ³n (RAG)
â”œâ”€â”€ github_llm.py        # ConexiÃ³n con la API de GitHub Models
â”œâ”€â”€ utils.py             # Carga y procesamiento de documentos
â”œâ”€â”€ docs/                # Documentos del curso (PDF, DOCX, TXT)
â”œâ”€â”€ data/                # Ãndice vectorial generado automÃ¡ticamente
â”œâ”€â”€ requirements.txt     # Lista de dependencias del proyecto
â”œâ”€â”€ .env.example         # Plantilla de variables de entorno
â””â”€â”€ README.md            # DocumentaciÃ³n del proyecto
```
**DescripciÃ³n general**

- app.py: Define la interfaz web del chatbot.
- rag.py: Implementa el flujo RAG (bÃºsqueda + generaciÃ³n).
- github_llm.py: Encapsula la comunicaciÃ³n con GitHub Models.
- utils.py: Maneja la lectura de documentos del curso.
- docs/: Carpeta donde el profesor coloca el material del curso.
- data/: Se crea automÃ¡ticamente al construir el Ã­ndice.
- requirements.txt: Permite instalar todas las dependencias con un solo comando.
- .env.example: GuÃ­a para configurar credenciales sin exponerlas.

## ğŸ“ Uso educativo

Esta plantilla es ideal para:

- Talleres de NLP
- Cursos universitarios
- PrÃ¡cticas controladas de IA
- Demostraciones de RAG

Los estudiantes solo pueden acceder al contenido definido por el profesor.

âš ï¸ Consideraciones

- Se requiere conexiÃ³n a Internet
- La primera indexaciÃ³n puede tardar algunos minutos
- Documentos grandes aumentan el tiempo de procesamiento

## ğŸ“œ Licencia

Este proyecto se proporciona con fines educativos y acadÃ©micos.

Puede adaptarse libremente para enseÃ±anza e investigaciÃ³n.

## ğŸ™Œ Agradecimientos

- GitHub Models
- Streamlit
- FAISS
- Sentence Transformers